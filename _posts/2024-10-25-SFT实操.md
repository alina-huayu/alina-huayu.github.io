---
layout: post
title: "SFT实操"
---

# 一. SFT的前提：
先把prompt engineering优化好，这个“好”是到什么程度呢——通过优化 prompt 已经不能解决剩余的 badcase。而且，由于SFT 数据集中也需要用到prompt，因此做 SFT之前要尽量把 prompt engineering做到最优。

# 二. 数据集准备：
训练集的质量比数量更重要。一开始不需要急着构造大量SFT数据集，可以先用少量数据（50条~100条）对模型做 SFT 后观察真实评估是否有收益。如果有收益，可以尝试以部分数据为种子数据集继续扩充，找到 scaling law。如果没有收益，那么再重新检查 SFT 数据集的质量。


那么什么样的数据才能算质量好呢？


以下面这【一条】示例数据（特点：多轮对话，用了ReAct方法提升planning效果，且在实际生产中会使用RAG）为例来讲解： 

实际应用中的数据要符合jsonl要求，即每行是一个json对象。这里换行是为了渲染成方便大家看的格式。

```json
{
  "messages": [
    {
      "role": "system",
      "content": "你是一个帮助前来咨询的用户解决他们问题的客服助手。每次收到用户的输入，你都需要根据知识库结果（knowledge base result），用 ReAct 方法思考出解决方案，然后答复用户。你的输出要包含两部分：思考过程和给用户的答复；其中，ReAct 思考过程要用（<>）包围起来。给用户的答复正常显示即可，不需要用（<>）包围起来。注意：不要只有第一次回复用户的时候使用ReAct方法，每次回复都要使用ReAct方法去思考。 ReAct 的方法是：1. 首先思考用户的问题该如何解决，给出你的推理，标记为思考。2. 然后根据你的推理决定合适的行动，标记为行动。3. 观察你行动的结果或收集必要的信息，标记为观察。"
    },
    {
      "role": "user",
      "content": "为什么我无法开直播？ Knowledge Base Result: 用户反馈无法开直播，如何处理？ 处理方法是：先确认用户是否在开播时收到了异常提示，即\"账号异常，无法开播\"。 
1. 如果用户收到了异常提示，要让用户自行核查账号是否存在历史违规。 
2. 如果用户没收到异常提示，要进一步询问用户的账号是否为大陆地区的账号。 
2.1 如果用户的账号不是大陆地区的账号，要告诉用户，非大陆地区暂无法开启直播。 
2.2 如果用户的账号是大陆地区账号，要进一步询问用户是否已完成实名认证。 
2.2.1 如果用户的账号没有完成实名认证，要告诉用户，需要完成实名认证才能开启直播。 
2.2.2 如果用户的账号已经完成实名认证，要进一步询问用户的实名认证是否依旧审核通过。 
2.2.2.1 如果用户的实名认证没有通过，要告诉用户，需要等实名认证通过后才能开启直播。 
2.2.2.2 如果用户的实名认证通过了但仍然无法开启直播，要为用户转接人工客服。"
    },
    {
      "role": "assistant",
      "content": "< 思考：根据知识库结果，我要先确认用户是否在开播时收到了异常提示，即\"账号异常，无法开播\"。 
动作：询问用户是否在开播时收到了异常提示，即\"账号异常，无法开播\"。 
观察：等用户返回是否收到了异常提示 > 
--- 请问您是否在开播时收到了异常提示，即\"账号异常，无法开播\"？"
    },
    {
      "role": "user",
      "content": "没有。 Knowledge Base Result: [同上]"
    },
    {
      "role": "assistant",
      "content": "< 思考：根据知识库结果，如果用户没收到异常提示，要进一步询问用户的账号是否为大陆地区的账号。
动作：询问用户的账号是否是大陆地区的账号。> 
--- 请问您的账号是大陆地区的账号吗？"
    },
    {
      "role": "user",
      "content": "是。 Knowledge Base Result: [同上]"
    },
    {
      "role": "assistant",
      "content": "< 思考：根据知识库结果，如果用户的账号是大陆地区的账号，要进一步询问用户的账号是否已完成实名认证。 
动作：询问用户的账号是否已完成实名认证。> 
--- 您的账号是否已完成实名认证呢？"
    },
    {
      "role": "user",
      "content": "完成了。 Knowledge Base Result: [同上]"
    },
    {
      "role": "assistant",
      "content": "< 思考：根据知识库结果，如果用户已经完成了实名认证，要进一步询问用户的实名认证是否审核通过了。 
动作：询问用户的实名认证是否审核通过了> 
--- 您的实名认证审核通过了吗？"
    },
    {
      "role": "user",
      "content": "通过了。 Knowledge Base Result: [同上]"
    },
    {
      "role": "assistant",
      "content": "< 思考：根据知识库结果，如果用户的实名认证通过了但仍然无法开启直播，要为用户转接人工客服。 
动作：为用户转接人工客服> 
--- 请稍等，为您转接人工客服。"
    }
  ]
}
```

1. 训练数据要足够有代表性：一个常见的问题就是用于SFT的样本在格式或者形式上与LLM在实际生产中看到的略有不同。
- 例如，如果你有一个检索增强生成（RAG）应用，那么你可以使用包含 RAG 相关段落的方式对模型进行SFT。可以看到：user message中我拼接了knowledge base result数据，模拟从知识库中retrieve来的数据，让大模型基于这些上下文来生成输出。


2. 如果训练数据存在噪声（如错别字、错误格式、不符合预期输出的样本等），那么会对模型的训练过程造成比较严重的影响。
- 例1：可以注意到，knowledge base result中的内容通过1.2.1这样的序号来清楚的表示层级。
- 例2: system message提示大模型要用ReAct方法来思考（ReAct方法就是让大模型按照思考-动作-观察，这样的步骤来自主思考，以提升Agent的规划能力）。assistant message中，有这样的一句示例：“动作：询问用户的账号是否是大陆地区的账号。” 这里如果写成：“动作：询问用户：您的账号是否是大陆地区的？” 一句中有两个冒号，这个结构就不够清晰——大模型就不容易理解到“询问用户：您的账号是否是大陆地区的？”都属于“动作”，对模型的训练效果有影响。

# 三. 模型选择：
首先，需要明确我们的模型使用场景是否对延迟比较敏感，如果对延迟比较敏感，那么需要选择推理速度快的模型。通常，参数量小的模型的推理速度会更快。而且我们可以通过模型蒸馏，来使小模型在某一特定场景下，达到与大模型相近的效果。

其次，需要明确我们的应用场景是否需要长文本能力。选择context window合适的模型。

# 四. 模型训练：
SFT时，超参数的选择也会影响模型训练的效果。常用的有以下三个：
- learning rate：学习率，设置较大时会加速模型迭代，但是模型可能无法收敛到最优点；设置过小时会使得模型迭代较慢，可能陷入局部最优。
- batch size：每次训练迭代使用的样本数。batch size要和训练集的量适配，如果训练集的量很大，那么batch size可以设置大一些，如果训练集的量很小，那么batch size可以设置小一些。
- epochs：模型训练轮数。假如epoch设置为2，那么模型就会把数据集训练2轮。

# 五. 模型评估：
有两种方法（可叠加用于判断，不可互相替代）：
- 训练过程中观察loss指标；
loss 指标：一般观察在训练集和验证集上的损失来评估模型精调的效果。
如果训练集 loss 曲线下降，验证集loss 曲线上升，则说明模型已经过拟合，此刻应该停止训练；如果训练集和验证集 loss 曲线均在缓慢下降，则说明模型还未收敛，可以继续训练。此外，对于文案生成，小说创作等生成类任务，由于某些上下文逻辑及风格不能通过 loss 体现，所以不应仅看 loss 来决定模型何时停止训练。
- 发布服务后在真实评估集上评估。详见我的另一篇分享——如何评估大模型的效果

