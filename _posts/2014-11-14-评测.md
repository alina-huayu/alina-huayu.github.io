---
layout: post
title: "LLM的效果如何评测？"
---

# 1. 明确评估目标：
-更好的理解大模型的长处和短处，定位模型问题：通过评估，找到模型在当前场景所存在的问题，而后进行分类归因。

- 找到有效的提升方案：基于定位的问题及归因分析，来找到有效的解决方案（如优化Prompt、借助工程手段、微调模型、提升私域知识质量等）。

- 监控效果状态，防范未知和可能的风险：大模型存在随机波动的特点，A版本模型可以顺利使用的Prompt，可能到B版本就失效了。因此，我们要在每个模型版本上，都针对已使用Prompt进行效果监控评估，防止出现“意料之外”的效果下降。

- 挖掘线上BadCase，优化应用效果：通过数据回流获得线上真实流量中的用户请求与应用返回结果（甚至针对多轮交互场景，跟踪收集每一轮次用户请求-响应数据） ，通过评估找到不符合预期的Case，并分析确定优化的方案。



   ![评分系统](/images/打分.jpg)

