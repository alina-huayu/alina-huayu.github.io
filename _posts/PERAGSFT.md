---
layout: post
title: "提升LLM效果-Prompt Engineering/RAG/SFT分别适合什么情况下使用"
---

1. Prompting Engineering
适合于：
  1. 成本低，见效快
  2. 作为优化的起点，建立一个基准（基准是指：优化到一定程度了，确定一个基准的评测集和评测结果），用于比较RAG/SFT等手段带来的提升的效果
不适合：
  1. 引入新的信息给模型
  2. 稳定持续的输出学习到的复杂方法、风格等
  3. 减少对context window的占用
  
2. RAG
适合于：
  1. 注入知识（时效性高的信息，或者特定领域的知识）
  2. 减少幻觉
不适合：
  1. 减少对context window的占用
  2. 稳定持续的输出学习到的复杂方法、风格等

3. SFT
适合于：
  1. 教模型学习一个复杂的行为，并可靠稳定的输出，比如：
    1. 遵从prompt效果不好，要SFT
    2. 有些任务不容易通过prompt描述清楚，可以准备很多示例来让模型理解和学会（比如语气、风格等）
  2. 减少对context window的占用
  3. 通过模型蒸馏节省成本，降低时延
不适合：
  1. 更新时效性高的信息

4. 纠正一个误区：有的人认为Prompt Engineering之后，必须是RAG，然后是SFT。
RAG和SFT解决的是不同的问题，RAG解决的是“模型需要知道什么信息”的问题，SFT解决的是“模型需要知道如何行动”的问题，两者没有次序，作用可以叠加。

5. 以上三个方法结合的最优策略：
  1. prompt尽量精简（但也要足够有效）以节约token（留token给RAG）
  2. 通过SFT来训练模型遵从指令和实施复杂动作的能力
  3. 通过RAG来注入所需的知识

