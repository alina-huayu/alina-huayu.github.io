---
layout: post
title: "通过哪些指标来衡量RAG的效果？"
---
大模型直接回复用户的问题，经常会存在以下问题：

1.缺乏特定领域的专业知识，无法解答专业性强的问题；

2.缺乏最新的信息，导致无法处理时效性要求高的问题；

3.容易产生幻觉。

检索增强生成（RAG）通过检索相关内容来增强生成的答案，有效的优化上述问题。当用户提出问题时，在让模型回答问题之前，我们会从知识库中检索出最相关的内容。检索到的内容会与用户的问题一起作为大模型的输入，来生成更准确的答案。

从RAG的过程我们可以看出，RAG的效果主要从以下两方面进行衡量：
- 检索（Retrieval）：即，RAG系统是否将正确的上下文呈现给了大模型。那么Retrieval用哪些指标来评估呢？
  - 精度：假如有10个段落被召回了，但是其中只有6个是真正相关的段落，那么精度是60%。精度反映的是：检索到的上下文的噪声比。
  - 召回率：假如在所有的知识库中，应该有12个相关段落被召回，但实际上只召回了6个相关段落。那么召回率是50%。 召回率反映的是：是否能召回问题所需的全部相关段落。
- 生成（Generation）：即，如果RAG系统将正确的上下文呈现给了大模型，大模型是否能生成高质量的输出。
  - 忠实度：生成的输出在多大程度上忠于原上下文，有没有不符合原上下文的事实性错误。
  - 回答的相关性：生成的输出与用户的问题的相关程度。